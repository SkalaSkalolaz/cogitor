// websearch.go
// –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: –ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ —á–µ—Ä–µ–∑ DuckDuckGo –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

package main

import (
	"fmt"
	"golang.org/x/net/html"
	"golang.org/x/net/html/charset"
	"net/http"
	"net/url"
	"strings"
	"time"
	"context"
)

// Link –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—É—é —Å—Å—ã–ª–∫—É
type Link struct {
	Title string
	URL   string
}

// SearchResult –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞ —Å –æ—Ü–µ–Ω–∫–æ–π –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏
type SearchResult struct {
	Query      string
	Content    string
	Sources    []Link
	Confidence int    // 0-100, –æ—Ü–µ–Ω–∫–∞ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏
	Summary    string // –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è
}

// LogSearchRequest –ª–æ–≥–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ –ø–æ–∏—Å–∫—É –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
func LogSearchRequest(query, reason string) {

	fmt.Printf("üåê LLM –∑–∞–ø—Ä–æ—Å–∏–ª –≤–µ–±-–ø–æ–∏—Å–∫: \"%s\"\n", query)
    fmt.Printf("   –ü—Ä–∏—á–∏–Ω–∞: %s\n", reason)
    fmt.Println("   –ü–æ–∏—Å–∫ —Ç–µ–∫—É—â–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏...")
}


// normalizeWhitespace collapses all whitespace (spaces, tabs, newlines) into single spaces.
func normalizeWhitespace(s string) string {
	return strings.Join(strings.Fields(s), " ")
}

// FetchTopText takes a search query, fetches the top 5 DuckDuckGo HTML results,
// retrieves visible text from each page, and returns the concatenated text.
func FetchTopText(ctx context.Context, query string) (*SearchResult, error) {
	fmt.Printf("üåê –ü–æ–∏—Å–∫: %s\n", query)
	

	links, err := fetchTopLinks(ctx, query)
	if err != nil {
		return nil, err
	}

	var texts []string
	var sources []Link
	limit := 5
	if len(links) < limit {
		limit = len(links)
	}
	
	for i := 0; i < limit; i++ {
		fmt.Printf("üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –∏–∑: %s\n", links[i].URL)

		t, err := fetchTextFromURLGoDuckSearch(ctx, links[i].URL)
		if err != nil {
			// –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø—Ä–∏ –æ—à–∏–±–∫–µ —á—Ç–µ–Ω–∏—è, –ø—Ä–æ–¥–æ–ª–∂–∞—è —Å –æ—Å—Ç–∞–ª—å–Ω—ã–º–∏
			fmt.Printf("‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ %s: %v\n", links[i].URL, err)
			continue
		}
		t = strings.TrimSpace(t)
		if t != "" {
			texts = append(texts, t)
			sources = append(sources, links[i])
		}
	}

	if len(texts) == 0 {
		return nil, fmt.Errorf("no content found for query: %s", query)
	}

	combined := strings.Join(texts, "\n\n")
	combined = normalizeWhitespace(combined)
	
	// –û—Ü–µ–Ω–∏–≤–∞–µ–º –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è
	confidence := estimateConfidence(sources, combined)
	
	result := &SearchResult{
		Query:      query,
		Content:    combined,
		Sources:    sources,
		Confidence: confidence,
		Summary:    generateSummary(combined),
	}
	
	fmt.Printf("‚úÖ –ü–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω: %d –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: %d%%\n", len(sources), confidence)
	return result, nil
}

// fetchTopLinks –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç DuckDuckGo HTML-–≤–µ—Ä—Å–∏—é –ø–æ–∏—Å–∫–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–≤—ã–µ 5 —Å—Å—ã–ª–æ–∫.
func fetchTopLinks(ctx context.Context, query string) ([]Link, error) {
	escaped := url.QueryEscape(query)
	searchURL := "https://duckduckgo.com/html/?q=" + escaped

	client := &http.Client{
		Timeout: 15 * time.Second,
	}
	
	// ‚úÖ –ò–°–ü–û–õ–¨–ó–£–ï–ú NewRequestWithContext
	req, err := http.NewRequestWithContext(ctx, "GET", searchURL, nil)
	if err != nil {
		return nil, err
	}
	
	req.Header.Set("User-Agent", "Mozilla/5.0 (compatible; AI-Code-Assistant/1.0; +https://github.com/aicode-assistant)")

	resp, err := client.Do(req)
	if err != nil {
		return nil, err
	}
	defer resp.Body.Close()
	if resp.StatusCode != http.StatusOK {
		return nil, fmt.Errorf("HTTP status: %d", resp.StatusCode)
	}

	// –î–µ–∫–æ–¥–∏—Ä—É–µ–º –≤ UTF-8 —Å–æ–≥–ª–∞—Å–Ω–æ –∑–∞–≥–æ–ª–æ–≤–∫—É Content-Type
	reader, err := charset.NewReader(resp.Body, resp.Header.Get("Content-Type"))
	if err != nil {
		return nil, err
	}
	doc, err := html.Parse(reader)
	if err != nil {
		return nil, err
	}

	var links []Link
	var f func(*html.Node)
	f = func(n *html.Node) {
		if n.Type == html.ElementNode && n.Data == "a" {
			var href string
			var class string
			for _, a := range n.Attr {
				if a.Key == "href" {
					href = a.Val
				}
				if a.Key == "class" {
					class = a.Val
				}
			}
			// DuckDuckGo —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —á–∞—Å—Ç–æ –∏–º–µ—é—Ç –∫–ª–∞—Å—Å "result__a"
			if strings.Contains(class, "result__a") && href != "" {
				title := extractText(n)
				finalURL := href
				// –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π URL —á–µ—Ä–µ–∑ uddg (–µ—Å–ª–∏ –µ—Å—Ç—å)
				if u, err := url.Parse(href); err == nil {
					if q, err := url.ParseQuery(u.RawQuery); err == nil {
						if uddg := q.Get("uddg"); uddg != "" {
							if decoded, err := url.QueryUnescape(uddg); err == nil {
								finalURL = decoded
							} else {
								finalURL = uddg
							}
						}
					}
					// –µ—Å–ª–∏ –∏—Ç–æ–≥–æ–≤—ã–π URL –≤—Å—ë –µ—â—ë –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –∞–±—Å–æ–ª—é—Ç–Ω—ã–π DDG URL
					if strings.HasPrefix(finalURL, "/") {
						finalURL = "https://duckduckgo.com" + finalURL
					}
				}
				// –µ—Å–ª–∏ —ç—Ç–æ –≤—Å—ë –µ—â—ë –Ω–µ http(s), –ø–æ–ø—ã—Ç–∞—Ç—å—Å—è —Å–¥–µ–ª–∞—Ç—å –ø–æ–ª–Ω—ã–π URL —á–µ—Ä–µ–∑ DDG –±–∞–∑—É
				if !strings.HasPrefix(finalURL, "http://") && !strings.HasPrefix(finalURL, "https://") && strings.HasPrefix(href, "/") {
					finalURL = "https://duckduckgo.com" + href
				}
				// –ø—Ä–æ–ø—É—Å—Ç–∏–º —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å–∞–º DDG
				if strings.Contains(finalURL, "duckduckgo.com") {
					// –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º
				} else {
					links = append(links, Link{Title: strings.TrimSpace(title), URL: finalURL})
				}
			}
		}
		for c := n.FirstChild; c != nil; c = c.NextSibling {
			f(c)
		}
	}
	f(doc)

	// –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø–µ—Ä–≤—ã–º–∏ 5 —Å—Å—ã–ª–∫–∞–º–∏
	if len(links) > 5 {
		links = links[:5]
	}
	return links, nil
}

// fetchTextFromURLGoDuckSearch –∑–∞–≥—Ä—É–∂–∞–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ—ë –≤–∏–¥–∏–º—ã–π —Ç–µ–∫—Å—Ç.
func fetchTextFromURLGoDuckSearch(ctx context.Context, pageURL string) (string, error) {
	client := &http.Client{
		Timeout: 20 * time.Second,
	}
	
	// ‚úÖ –ò–°–ü–û–õ–¨–ó–£–ï–ú NewRequestWithContext
	req, err := http.NewRequestWithContext(ctx, "GET", pageURL, nil)
	if err != nil {
		return "", err
	}
	
	req.Header.Set("User-Agent", "Mozilla/5.0 (compatible; AI-Code-Assistant/1.0; +https://github.com/aicode-assistant)")

	resp, err := client.Do(req)
	if err != nil {
		return "", err
	}
	defer resp.Body.Close()
	// –ü—Ä–æ—Å—Ç–æ–π –æ—Ç–≤–µ—Ç-–æ–±—Ä–∞–±–æ—Ç—á–∏–∫
	if resp.StatusCode != http.StatusOK {
		return "", fmt.Errorf("HTTP status: %d", resp.StatusCode)
	}

	// –î–µ–∫–æ–¥–∏—Ä—É–µ–º –≤ UTF-8
	reader, err := charset.NewReader(resp.Body, resp.Header.Get("Content-Type"))
	if err != nil {
		return "", err
	}
	doc, err := html.Parse(reader)
	if err != nil {
		return "", err
	}

	text := extractText(doc)
	// normalize whitespace
	text = normalizeWhitespace(text)
	return text, nil
}

// extractText —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ —Å–æ–±–∏—Ä–∞–µ—Ç –≤–∏–¥–∏–º—ã–π —Ç–µ–∫—Å—Ç –∏–∑ HTML-—É–∑–ª–∞.
func extractText(n *html.Node) string {
	var b strings.Builder
	var walk func(*html.Node)
	walk = func(node *html.Node) {
		// –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–∫—Ä–∏–ø—Ç—ã –∏ —Å—Ç–∏–ª–∏
		if node.Type == html.ElementNode && (node.Data == "script" || node.Data == "style" || node.Data == "nav" || node.Data == "header" || node.Data == "footer") {
			return
		}
		if node.Type == html.TextNode {
			// –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
			text := strings.TrimSpace(node.Data)
			if text != "" {
				b.WriteString(text)
				b.WriteByte(' ')
			}
		}
		for c := node.FirstChild; c != nil; c = c.NextSibling {
			walk(c)
		}
	}
	walk(n)
	return b.String()
}

// estimateConfidence –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
func estimateConfidence(sources []Link, content string) int {
	// –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
	confidence := len(sources) * 15
	if confidence > 60 {
		confidence = 60
	}

	// –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
	content = strings.ToLower(content)
	
	// –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
	positiveSignals := []string{
		"official", "documentation", "github.com", "stackoverflow", "w3.org", ".gov",
		"mozilla", "developer", "tutorial", "guide", "example", "sample",
		"–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π", "–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è", "github.com", "stackoverflow", "w3.org",
		"mozilla", "–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å", "–æ–ø–∏—Å–∞–Ω–∏–µ", "—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ", "–ø—Ä–∏–º–µ—Ä", "–æ–±—Ä–∞–∑–µ—Ü",
			
	}
	
	// –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
	negativeSignals := []string{
		"click here", "download now", "buy now", "limited time", "advertisement",
		"sponsored", "popup", "sign up", "subscribe", "—Å–ø–æ–Ω—Å–æ—Ä",
	}
	
	for _, signal := range positiveSignals {
		if strings.Contains(content, signal) {
			confidence += 5
		}
	}
	
	for _, signal := range negativeSignals {
		if strings.Contains(content, signal) {
			confidence -= 10
		}
	}
	
	// –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω
	if confidence < 10 {
		confidence = 10
	}
	if confidence > 95 {
		confidence = 95
	}
	
	return confidence
}

// generateSummary –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
func generateSummary(content string) string {
	if len(content) > 500 {
		return content[:500] + "..."
	}
	return content
}

// ShouldSearch –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–µ–Ω –ª–∏ –ø–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞
func ShouldSearch(question, language string) (bool, string) {
	lowerQuestion := strings.ToLower(question)

	normalizedQuestion := " " + lowerQuestion + " "

	// –§—Ä–∞–∑—ã, –∫–æ—Ç–æ—Ä—ã–µ –ó–ê–ü–†–ï–©–ê–Æ–¢ –ø–æ–∏—Å–∫ (–ø—Ä–æ–≤–µ—Ä—è–µ–º –≤ –ø–µ—Ä–≤—É—é –æ—á–µ—Ä–µ–¥—å!)
	searchBlockingPhrases := []string{
		"–Ω–∞–ø–∏—à–∏ –∫–æ–¥",
		"–Ω–∞–ø–∏—à–∏ –ø—Ä–æ–≥—Ä–∞–º–º—É", 
		"—Å–æ–∑–¥–∞–π —Ñ–∞–π–ª",
		"–ø–µ—Ä–µ–ø–∏—à–∏ –∫–æ–¥",
		"–∏–∑–º–µ–Ω–∏ –∫–æ–¥",
		"–¥–æ–±–∞–≤—å —Ñ—É–Ω–∫—Ü–∏—é",
		"—Ä–µ–∞–ª–∏–∑—É–π",
		// –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ –∞–Ω–∞–ª–æ–≥–∏ –¥–ª—è –ø–æ–ª–Ω–æ—Ç—ã
		"write code",
		"write program",
		"create file",
		"rewrite code",
		"modify code",
		"add function",
		"implement",
	}

	// –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–ª–æ–∫–∏—Ä—É—é—â–∏–µ —Ñ—Ä–∞–∑—ã
	for _, phrase := range searchBlockingPhrases {
		// –ë–æ–ª–µ–µ —Ç–æ—á–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å —É—á–µ—Ç–æ–º –≥—Ä–∞–Ω–∏—Ü —Å–ª–æ–≤
		if strings.Contains(normalizedQuestion, " "+phrase+" ") ||
			strings.HasPrefix(lowerQuestion, phrase+" ") ||
			strings.HasSuffix(lowerQuestion, " "+phrase) {
			// return false, "no_search_needed"
			return false, "search_blocked_by_phrase"
		}
	}


	// –¢–µ–º—ã, —Ç—Ä–µ–±—É—é—â–∏–µ –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
	topicsNeedingCurrentInfo := []string{
		"latest", "recent", "current", "new", "update", "version",
		"today", "2024", "2025", "2026", "modern", "trend", "best practice", "–Ω–∞–π–¥–∏ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ",
		"recent change", "new feature", "release", "deprecated",
		"–ø–æ—Å–ª–µ–¥–Ω–∏–π", "—Ç–µ–∫—É—â–∏–π", "–Ω–æ–≤—ã–π", "–Ω–æ–≤–æ—Å—Ç–∏", "–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ", "–≤–µ—Ä—Å–∏—è",
		"—Å–µ–≥–æ–¥–Ω—è", "—Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π", "—Ç—Ä–µ–Ω–¥", "–ª—É—á—à–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞",
		"–Ω–µ–¥–∞–≤–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è", "–Ω–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è", "–≤—ã–ø—É—Å–∫", "—É—Å—Ç–∞—Ä–µ–ª–æ",
	}
	
	// –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ–º—ã, —Ç—Ä–µ–±—É—é—â–∏–µ –ø–æ–∏—Å–∫–∞
	technicalTopics := []string{
		"how to", "tutorial", "guide", "example", "sample code",
		"documentation", "api reference", "library", "package",
		"framework", "tool", "installation", "setup", "configuration",
		"—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ",
		"–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è", "—Å—Å—ã–ª–∫–∞ –Ω–∞ API", "–±–∏–±–ª–∏–æ—Ç–µ–∫–∞", "–ø–∞–∫–µ—Ç",
		"—Ñ—Ä–µ–π–º–≤–æ—Ä–∫", "–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç", "—É—Å—Ç–∞–Ω–æ–≤–∫–∞", "–Ω–∞—Å—Ç—Ä–æ–π–∫–∞", "–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è",
	}
	
	// –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–∞ –ª–∏ –∞–∫—Ç—É–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
	for _, topic := range topicsNeedingCurrentInfo {
		if strings.Contains(lowerQuestion, topic) {
			return true, "question_requires_current_info"
		}
	}
	
	// –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ–º—ã
	for _, topic := range technicalTopics {
		if strings.Contains(lowerQuestion, topic) {
			return true, "technical_topic_requires_docs"
		}
	}
	
	// –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è —è–∑—ã–∫–æ–≤ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ–º—ã
	languageSpecificSearch := map[string][]string{
		"go": {"go mod", "go get", "goroutine", "channel", "interface", "struct"},
		"python": {"pip install", "virtualenv", "decorator", "list comprehension", 
		          "pandas", "numpy", "django", "flask"},
		"javascript": {"npm install", "react", "vue", "angular", "node.js", 
		             "express", "webpack", "babel"},
		"java": {"maven", "gradle", "spring", "hibernate", "jpa", "servlet"},
	}
	
	if topics, exists := languageSpecificSearch[language]; exists {
		for _, topic := range topics {
			if strings.Contains(lowerQuestion, strings.ToLower(topic)) {
				return true, "language_specific_topic"
			}
		}
	}
	
	return false, "no_search_needed"
}